{"cells":[{"cell_type":"markdown","metadata":{"id":"F5Exz32-J_-5"},"source":["# Can **you** break computer vision model?\n","## On-site round"]},{"cell_type":"markdown","metadata":{"id":"DNIfM-c5akQn"},"source":["## Task 1: Break a network by hand\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WYVd3-MsSMLQ"},"source":["Suppose you have a neural network $M$, defined b $M(x) = \\text{softmax}\\left(x^\\top\\theta\\right)$. Note that for $z\\in\\mathbb{R}^n$ we have $\\text{softmax}(z)=\\frac{1}{\\sum_i \\exp(z_i)}\\cdot\\left[\\exp(z_1), \\exp(z_2), \\ldots, \\exp(z_n)\\right]$.\n","\n","Further, let $x=[1.,2.,3.]$ be an input of interest and let $\\theta=\\begin{bmatrix}\n","    5. & -2. \\\\\n","    3. & 4. \\\\\n","    2. & -1.\n","\\end{bmatrix}$. Compute an an adversarial example $x^\\prime$ that maximizes the second coordinate of $M(x)$ under the constraint that $\\|x^\\prime-x\\|_\\infty \\leq 1.$, i.e., you're creating an $\\ell_\\infty$ adversarial example with $\\varepsilon=1$."]},{"cell_type":"markdown","metadata":{"id":"L5qxvfm7Wjm6"},"source":["Your solution here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kNj45s0ERR5D"},"source":["## Task 2: Alice heard you've attacked her latest model, so she created a new one! Can you break that one too?\n","\n","Alice heard about your adaptive attack on AliceNet, so she's raised the bar with her latest robust model, AliceNetV2. According to her, there's no way to attack this new model!\n","Like last time, Alice won't share with you what her defense is!\n","\n","Your task is to develop an adaptive *targeted* attack. In particular, you must find a way to make small perturbations to the input images such that AliceNetV2 outputs the class \"dog\" every time!\n","\n","###Task Requirements\n","\n","1. **Understand the Defense**: Analyze Alice's model to understand the type of defense implemented. This could involve reviewing the model architecture, preprocessing steps, or any additional mechanisms employed for defense.\n","\n","2. **Design an Adaptive Targeted Attack**: Develop an attack strategy that goes around Alice's defense and makes AliceNetV2 output the calss \"dog\". This might involve modifying standard attack methods like PGD.\n","\n","3. **Generate Adversarial Examples**: Modify all test images from the CIFAR-10 dataset using your adversarial attack. You are allowed to modify the original test images within an $\\ell_\\infty$ ball of radius $8/255$.\n","\n","4. **Test Model Accuracy**: Evaluate how often the AliceNetV2 model predicts the label \"dog\" on these adversarially modified images.\n","\n","\n","###Deliverables\n","\n","* Python code used for your attack and generation of the adversarial CIFAR-10 test set.\n","* A short (up to a few paragraphs) report detailing your analysis of the defense, the approach used for the adaptive attack, and the success rate of your attack on the CIFAR-10 test set.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1714,"status":"ok","timestamp":1718542648275,"user":{"displayName":"olimp ai23","userId":"09396442386257444673"},"user_tz":-120},"id":"n2Y2ZlQGV1VC","outputId":"1bf45206-dc2c-4d20-d452-e11193e9d0e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n","    conflicts = self._determine_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n","    return check_install_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n","    package_set, _ = create_package_set_from_installed()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n","    dependencies = list(dist.iter_dependencies())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n","    return self._dist.requires(extras)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n","    super(Requirement, self).__init__(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n","    req = REQUIREMENT.parseString(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 862, in _parseNoCache\n","    ret_tokens = ParseResults(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 142, in __new__\n","    self._all_names = set()\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n","    logger.debug(\"Exception information:\", exc_info=True)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n","    formatted = super().format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n","    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n","  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n","    self.stack = StackSummary.extract(\n","  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n","    f.line\n","  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n","    self._line = linecache.getline(self.filename, self.lineno)\n","  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n","    first = read_or_stop()\n","  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n","    return readline()\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install wget\n","import wget"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ugEPnYK3fSL"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import functools\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(\n","            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(\n","                    in_planes,\n","                    self.expansion * planes,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False,\n","                ),\n","                nn.BatchNorm2d(self.expansion * planes),\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        return F.relu(out)\n","\n","\n","\n","def recursive_getattr(obj, attr, *args):\n","    def _getattr(obj, attr):\n","        return getattr(obj, attr, *args)\n","\n","    return functools.reduce(_getattr, [obj] + attr.split(\".\"))\n","\n","\n","class AliceNetV2_inner(nn.Module):\n","    KERNEL_SIZE = 3\n","    IN_CHANNELS = 3\n","    AVG_POOL_SIZE = 8\n","    LINEAR_MUL = 4 * 4\n","\n","    def __init__(self, num_blocks=2, in_planes=64, num_classes=10, debug=False):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.debug = debug\n","        self.in_planes = in_planes\n","        self.kernel_size = self.KERNEL_SIZE\n","        self.num_blocks = num_blocks\n","\n","        # pre-layer stuff\n","        self.conv1 = nn.Conv2d(\n","            self.IN_CHANNELS,\n","            self.in_planes,\n","            kernel_size=self.kernel_size,\n","            stride=1,\n","            padding=1,\n","            bias=False,\n","        )\n","        self.bn1 = nn.BatchNorm2d(self.in_planes)\n","\n","        # make single layer with K BasicBlocks\n","        # BasicBLock: conv1, bn1, conv2, bn2, shortcut\n","        # each conv has `in_planes` filters\n","        get_block = lambda: BasicBlock(self.in_planes, self.in_planes, stride=1)\n","        self.layer = nn.Sequential(*[get_block() for _ in range(num_blocks)])\n","\n","        # register blocks with setattr to make it compatible with masking code\n","        for idx, block in enumerate(self.layer):\n","            setattr(self, f\"block{idx}\", block)\n","\n","        # post-layer stuff\n","        self.flatten = nn.Flatten()\n","        self.avg_pool_2d = nn.AvgPool2d(self.AVG_POOL_SIZE)\n","        self.linear = nn.Linear(self.in_planes * self.LINEAR_MUL, num_classes)\n","\n","    def forward(self, x, *args, **kwargs):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        if self.debug:\n","            print(f\"conv1: {out.shape}\")\n","        out = self.layer(out)\n","        if self.debug:\n","            print(f\"layer: {out.shape}\")\n","        out = self.avg_pool_2d(out)\n","        if self.debug:\n","            print(f\"avg_pool_2d: {out.shape}\")\n","        out = self.flatten(out)\n","        out = self.linear(out)\n","        return out\n","\n","    def get_components(self, add_weight_suffix=True):\n","        comps = [\"conv1\"]\n","        num_convs = 2\n","        for block_idx in range(self.num_blocks):\n","            for conv_idx in range(1, 1 + num_convs):\n","                comps.append(f\"block{block_idx}.conv{conv_idx}\")\n","\n","        comps.append(\"linear\")\n","\n","        if add_weight_suffix:\n","            return [\"{}.weight\".format(c) for c in comps]\n","        return comps\n","\n","    def get_component_dimensions(self):\n","        comps = self.get_components()\n","        comps_map = {}\n","\n","        for c in comps:\n","            w = recursive_getattr(self, c)\n","            comps_map[c] = w.shape[0]\n","\n","        return comps_map\n","\n","class AliceNetV2(nn.Module):\n","    def __init__(self, num_blocks=2, in_planes=64, num_classes=10):\n","        super(AliceNetV2, self).__init__()\n","        self.model1 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n","        self.model2 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n","        self.model3 = AliceNetV2_inner(num_blocks=num_blocks, in_planes=in_planes, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        outputs = []\n","        for network in [self.model1, self.model2, self.model3]:\n","            out = network(x)\n","            outputs.append(out)\n","        outputs = torch.stack(outputs)\n","        network_predictions = torch.argmax(outputs, dim=-1)\n","        majority_votes = torch.mode(network_predictions, dim=0).values\n","        result = torch.zeros_like(out)\n","        for i, vote in enumerate(majority_votes):\n","            result[i, vote] = 1.\n","        return result\n","\n","\n","def get_alicenet_v2() -> AliceNetV2:\n","\n","    model = AliceNetV2()\n","\n","    # url = 'https://www.dropbox.com/scl/fi/awpcptjv4jbrgljn58k0m/alice_model_v2_IOAI.pt?rlkey=1v9hzkkpyqm0xqcyl1dogfwz8&dl=1'\n","    # wget.download(url, out='./alicenet_v2.pt', bar=None)\n","    trained_ckpt = torch.load('./alicenet_v2.pt', map_location=\"cpu\")\n","    model.load_state_dict(trained_ckpt)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNTgc9ZK83LP"},"outputs":[],"source":["import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","\n","alicenetv2 = get_alicenet_v2().to(\"cuda\")\n","\n","# umieszczenie tego w eval zmienia działanie\n","# posiedź nad tym\n","# alicenetv2.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2149,"status":"ok","timestamp":1718542650422,"user":{"displayName":"olimp ai23","userId":"09396442386257444673"},"user_tz":-120},"id":"-2WH8NP7ectD","outputId":"bb4a0079-e6f2-4857-906f-c05e269a589b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n","valid_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718542650422,"user":{"displayName":"olimp ai23","userId":"09396442386257444673"},"user_tz":-120},"id":"XmiVnMjA1LgS","outputId":"8dfe190d-3d66-49f1-dc7c-a719e1472578"},"outputs":[{"name":"stdout","output_type":"stream","text":["10000\n"]}],"source":["print(len(valid_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":501},"executionInfo":{"elapsed":19431,"status":"error","timestamp":1718542646565,"user":{"displayName":"olimp ai23","userId":"09396442386257444673"},"user_tz":-120},"id":"XUYUzDu1-iO5","outputId":"78d63823-0b3c-42e0-840c-0ba907e27564"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.5625, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.5625, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.5000, device='cuda:0')\n","tensor(0.5625, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.4375, device='cuda:0')\n","tensor(0.5625, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.9375, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(1., device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8750, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.6875, device='cuda:0')\n","tensor(0.7500, device='cuda:0')\n","tensor(0.8125, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n","tensor(0.6250, device='cuda:0')\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-501c6dbf34bf>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0;31m# Zmień to na ludzką formę\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;31m# labels[:, 5] = 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0;31m# print(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;31m# exit(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def norm(x):\n","    x = (0.5 - x) * 2\n","\n","    # Obliczamy długości wektorów wzdłuż osi kanałów (axis=1)\n","    vector_lengths = torch.norm(x, dim=1, keepdim=True)  # [batch_size x 1 x 32 x 32]\n","\n","    # Znajdujemy maksymalną długość wektora w całym batchu\n","    max_vector_length = vector_lengths.max()\n","\n","    # Ustalamy współczynnik normalizacji\n","    normalization_factor = (8.0 / 255.0) / max_vector_length\n","\n","    # Normalizujemy tensor x\n","    x = x * normalization_factor\n","\n","    return x\n","\n","t_loss = 0\n","t_loss_num = 0\n","\n","# Zapisz ten plik i zamień na model\n","num_epochs = 1000\n","criterion = torch.nn.CrossEntropyLoss()\n","for i, (image, target) in enumerate(val_dataloader):\n","  image = image.to(\"cuda\")\n","  target = target.to(\"cuda\")\n","\n","\n","\n","  x = torch.rand(image.shape).to(\"cuda\")\n","  x.requires_grad_(True)\n","  opt = torch.optim.Adam([x], lr=0.1)\n","\n","  for epoch in range(num_epochs):\n","      ni = image + norm(x)\n","\n","      # Upewnij się że modele alicenet nie są trenowane\n","      t1 = alicenetv2.model1(ni)\n","      t2 = alicenetv2.model2(ni)\n","      t3 = alicenetv2.model3(ni)\n","\n","      # labels = torch.zeros(image.shape[0], 10).to(\"cuda\")\n","\n","      # Zmień to na ludzką formę\n","      # labels[:, 5] = 1.0\n","      labels = torch.full((image.shape[0],), 5).to(\"cuda\")\n","      # print(labels)\n","      # exit(0)\n","\n","      loss1 = criterion(t1, labels)\n","      loss2 = criterion(t2, labels)\n","      loss3 = criterion(t3, labels)\n","\n","      opt.zero_grad()\n","      # loss = loss1 + loss2 + loss3\n","      # loss.backward()\n","\n","      loss1.backward(retain_graph=True)\n","      loss2.backward(retain_graph=True)\n","      loss3.backward()\n","\n","      opt.step()\n","\n","  # Średnia != głosowanie - popraw\n","  args = torch.argmax(alicenetv2(ni), dim=-1)\n","\n","  args2 = torch.full(args.shape, 5).to(\"cuda\")\n","  print(torch.sum(args == args2)/len(args))\n","\n","  t_loss += torch.sum(args == args2)\n","  t_loss_num += len(args)\n","\n","print(\"TOTAL\")\n","print(t_loss/t_loss_num)\n","\n","  # for epoch in range(num_epochs):\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}